{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyDesigner Example\n",
    "This notebook serves to educate on PyDesigner and it's usage. Currently, this example will only cover portions past preprocessing for stability testing of **dwipi**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules\n",
    "Start by loading modules necessary to execute this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from fitting import dwipi as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Paths\n",
    "First define paths - to read and save images. There are primarily two paths defined for testing:\n",
    "1. `niiPath`: path to preprocessed NifTi file\n",
    "2. `outDir`:  output directory where maps will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "niiPath = '/Users/sid/Documents/Projects/IAM/Dataset/Processed/IAM_1009/dwi_designer.nii'\n",
    "savePath = '/Users/sid/Documents/Projects/IAM/Dataset/Processed/IAM_1009/metrics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DWI Class\n",
    "The `DWI` class holds information on the NifTi image. Initialize is done by loading the image and it's dependencies to memory. These attributes are:\n",
    "\n",
    "1. **img**: The diffusuion weighted image (DWI) itself\n",
    "2. **grad**:Gradient table with 4 columns [X, Y, Z, B-Value]\n",
    "4. **hdr**: NifTI header information\n",
    "5. **mask**: Brain mask\n",
    "6. **maskStatus**: Mask status indicating whether a brain mask is present or not\n",
    "\n",
    "Additional attributes will be added to this class depending on the method being called. For example, running class.fit() create a class.dt attribute within the DWI class.\n",
    "\n",
    "### Why so classy?\n",
    "Classes allow complete isolation of an image and it's primary attributes. This is helpful when processing multiple DWIs for comparison. You can create as many DWI class objects as you wish and still keep track of all esential parameters making up those DWI.\n",
    "\n",
    "### Onto making DWI class\n",
    "Let's start by craeting our first DWI class object. We previously defined a path to a NifTi file, let's use this to load a DWI class object. We can then print this class' attributes to demonstrate the information it's currently holding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No brain mask supplied\n",
      "Image dwi_designer.nii loaded successfully\n",
      "Processing with 16 workers...\n",
      "dict_keys(['hdr', 'img', 'grad', 'mask', 'maskStatus', 'workers'])\n"
     ]
    }
   ],
   "source": [
    "myimage = dp.DWI(niiPath)\n",
    "print(myimage.__dict__.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be safe, let's also plot the raw DWI images just to prove that they have indeed been loaded into memory ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 16), dpi= 80)\n",
    "img1 = fig.add_subplot(1,3,1)\n",
    "img1.imshow(myimage.img[:,:,30,0])    # Plot first volume, slice 30 (B0)\n",
    "img1.title.set_text('B0')\n",
    "img1.axis('off')\n",
    "img2 = fig.add_subplot(1,3,2)\n",
    "img2.imshow(myimage.img[:,:,30,10])   # Plot 10th volume, slice 30 (B1000)\n",
    "img2.title.set_text('B1000')\n",
    "img2.axis('off')\n",
    "img3 = fig.add_subplot(1,3,3)\n",
    "img3.imshow(myimage.img[:,:,30,70])  # Plot 70th volume, slice 30 (B2000)\n",
    "img3.title.set_text('B2000')\n",
    "img3.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazing!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Sequence\n",
    "The ideal fitting sequence should minimize the effects of noise on tensor estimation. We do this by first computing the IRLLS outliers, followed by constrained tensor estimation by excluding outliers. This can be done quite simply given the class object. Watch and learn.\n",
    "\n",
    "### Outlier Detection with Iterative Reweighted Linear Least Squares (IRLLS)\n",
    "This is a method of computing iteratively optimizing a tensor until a convergence point is reaced. The good-of-fit (GOF) is then tested and voxels that deviate far from GOF are marked as outliers. These voxels manipulate the accuracy of tensor estimation and thus are excluded from constrained tensor fitting.\n",
    "\n",
    "Running IRLLS is as simple as calling `myimage.irlls()`. Default values have been optimized so absolutely no input is required. Easy as that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IRLLS: Noise Estimation : 100%|█| 94185/94185 [00:05<00:00, 18817.98vox/s]\n",
      "IRLLS: Outlier Detection: 100%|█| 94185/94185 [00:45<00:00, 2054.85vox/s]\n"
     ]
    }
   ],
   "source": [
    "outliers, dt_hat = myimage.irlls()    # Produce 4D outlier map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy, wasn't it? Let's take a look at some of these outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 16), dpi= 80)\n",
    "img1 = fig.add_subplot(1,3,1)\n",
    "img1.imshow(outliers[:,:,30,0])       # Plot first volume, slice 30 (B0)\n",
    "img1.title.set_text('B0')\n",
    "img1.axis('off')\n",
    "img2 = fig.add_subplot(1,3,2)\n",
    "img2.imshow(outliers[:,:,30,10])      # Plot 10th volume, slice 30 (B1000)\n",
    "img2.title.set_text('B1000')\n",
    "img2.axis('off')\n",
    "img3 = fig.add_subplot(1,3,3)\n",
    "img3.imshow(outliers[:,:,30,100])     # Plot 100th volume, slice 30 (B2000)\n",
    "img3.title.set_text('B2000')\n",
    "img3.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show voxels that are outliers on the same volumes and sliices as the previous figure. These outlier voxels are not used in the estimation of diffusion tensor to maintain accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Estimation\n",
    "Now that you witnessed how easy it is to run this pipeline, let's do the same for tensor estimation. This is done using `myimage.fit()`. Easy enough? Sure! by default, providing no inputs performs unconstrained tensor fitting without outlier exclusion. However, constraining is as easy as providing as constraint vector, while outlier exclusion can be performed by providing the outlier map. Let's get to it!\n",
    "\n",
    "Take not, this is one of the class methods that adds essential class attributes for further computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constrained Tensor Fit  :  22%|▏| 85611/387200 [01:39<04:08, 1214.85vox/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0390b2b490f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Repos/PyDesigner/designer/fitting/dwipi.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, constraints, reject, dt_hat)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                              \u001b[0mdwi_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mreject_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mreject_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m                                              cons=C) for i in inputs)\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'processes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dmri/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dmri/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dmri/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dmri/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dmri/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myimage.fit(constraints=[0,1,0], reject=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's print the all attributes withing the DWI class to see what else has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(myimage.__dict__.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running tensor estimation has added three additional attributes:\n",
    "1. **b**: not sure at the moment :S\n",
    "2. **dt**: the ketchup to my steak, diffusion tensor\n",
    "3. **s0**: signal intensity for B0\n",
    "\n",
    "The addition of these attributes allow further caluculations to take palce within the DWI class object itself, thereby maintain isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Tensors\n",
    "Let's take a look at some of these tensors. The `DWI` object contains a `reorderTensor(imgType)` method that outputs diffusion or kurtosis tensors in MRTRIX3's format, depending on the parameter provided.\n",
    "\n",
    "In addition, detection of whether an image is DTI or DKI is handled by `tensorType()`, which outputs a string indicating the type of tensor. See the examples below for a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Shape of DT tensor is ' + np.str(DT.shape))\n",
    "# print('Shape of KT tensor is ' + np.str(KT.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('This is a ' + myimage.tensorType().upper() + ' image')\n",
    "\n",
    "# DT, KT = myimage.tensorReorder(myimage.tensorType())\n",
    "\n",
    "# fig = plt.figure(figsize=(18, 16), dpi= 80)\n",
    "# img1 = fig.add_subplot(1,2,1)\n",
    "# img1.imshow(DT[:,:,30,1]) \n",
    "# img1.title.set_text('DT 2 2')\n",
    "# img1.axis('off')\n",
    "# img2 = fig.add_subplot(1,2,2)\n",
    "# img2.imshow(KT[:,:,30, 7])   \n",
    "# img2.title.set_text('K  2 2 2 2')\n",
    "# img2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started the code above by printing the type of image in upper case, as handled by `tensorType()` method. Next, this information was parsed into `tensorReorder` method to generate MRTRIX-compatible DT and KT tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Estimation\n",
    "The difufsion tensor allows us to calculate diffusion and kurtosis parameters. The next method we'll investigate is `myimage.extract()`. As the name implies, this is used for extracting parameter maps from the tensor.\n",
    "\n",
    "Because not all maps may be require, this method requires returns to be clearly defined. In this example, we'll compute all possible maps. Let's juice the tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md, rd, ad, fa, fe, trace = myimage.extractDTI()\n",
    "\n",
    "akc_out = myimage.akcoutliers()\n",
    "myimage.akccorrect(akc_out=akc_out)\n",
    "\n",
    "mk, rk, ak, trace = myimage.extractDKI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdPath = os.path.join(savePath, 'MD.nii')\n",
    "rdPath = os.path.join(savePath, 'RD.nii')\n",
    "adPath = os.path.join(savePath, 'AD.nii')\n",
    "faPath = os.path.join(savePath, 'FA.nii')\n",
    "fePath = os.path.join(savePath, 'FE.nii')\n",
    "tracePath = os.path.join(savePath, 'Trace.nii')\n",
    "mkPath = os.path.join(savePath, 'MK.nii')\n",
    "rkPath = os.path.join(savePath, 'RK.nii')\n",
    "akPath = os.path.join(savePath, 'AK.nii')\n",
    "outlierPath = os.path.join(savePath, 'Outliers_IRLLS.nii')\n",
    "akcPath = os.path.join(savePath, 'Outliers_AKC.nii')\n",
    "dp.writeNii(md, myimage.hdr, mdPath)\n",
    "dp.writeNii(rd, myimage.hdr, rdPath)\n",
    "dp.writeNii(ad, myimage.hdr, adPath)\n",
    "dp.writeNii(fa, myimage.hdr, faPath)\n",
    "dp.writeNii(fe, myimage.hdr, fePath)\n",
    "dp.writeNii(trace, myimage.hdr, tracePath)\n",
    "dp.writeNii(mk, myimage.hdr, mkPath)\n",
    "dp.writeNii(rk, myimage.hdr, rkPath)\n",
    "dp.writeNii(ak, myimage.hdr, akPath)\n",
    "dp.writeNii(akc_out, myimage.hdr, akcPath)\n",
    "dp.writeNii(outliers, myimage.hdr, outlierPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have eight maps that can be easily visualized. However, some of these maps may require clipping because there may be values outside of favorable range. Let's look at the minimmum and maximum values of mean kurtosis (MK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('min(MK): ' + np.str(np.min(mk.reshape(-1))))\n",
    "# print('max(MK): ' + np.str(np.max(mk.reshape(-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are clearly outside of visualizable range, so we'll clip them using the `dwipi.clipImage` function. This function clips images based on a range vector, inclusive of input values. Let's clip this MK image and show before and after, at the same slice as all other brain images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mk_clipped = dp.clipImage(mk, [0, 2])\n",
    "# print('min(MK): ' + np.str(np.min(mk_clipped.reshape(-1))))\n",
    "# print('max(MK): ' + np.str(np.max(mk_clipped.reshape(-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new min and max values show that MK has indeed been clipped. Let's plot FA, MD, and MK for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(18, 16), dpi= 80)\n",
    "# img1 = fig.add_subplot(1,3,1)\n",
    "# img1.imshow(fa[:,:,30]) \n",
    "# img1.title.set_text('FA')\n",
    "# img1.axis('off')\n",
    "# img2 = fig.add_subplot(1,3,2)\n",
    "# img2.imshow(md[:,:,30])   \n",
    "# img2.title.set_text('MD')\n",
    "# img2.axis('off')\n",
    "# img3 = fig.add_subplot(1,3,3)\n",
    "# img3.imshow(mk_clipped[:,:,30])     \n",
    "# img3.title.set_text('MK')\n",
    "# img3.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Superb!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Entire Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inPath = '/Users/sid/Documents/Projects/IAM/Dataset/NifTi/IAM_1009/17_DKI_BIPOLAR_2_5mm_64dir_50slices.nii'\n",
    "# outPath = '/Users/sid/Documents/Projects/IAM/Dataset/Processed/IAM_1009'\n",
    "# topupPath = '/Users/sid/Documents/Projects/IAM/Dataset/NifTi/IAM_1009/18_DKI_BIPOLAR_2_5mm_64dir_50slices_TOP_UP_PA.nii'\n",
    "# cmd = 'python pydesigner.py --denoise --degibbs --undistort --topup ' + \\\n",
    "# topupPath + '--smooth --rician --verbose ' + \\\n",
    "# inPath + ' -o ' + outPath\n",
    "# print(cmd)\n",
    "# os.system(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
